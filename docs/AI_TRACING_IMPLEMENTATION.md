# AI Tracing & Cost Monitoring - Implementation Status

## ‚úÖ Implemented

### 1. AI Tracer Service (`server/ai/aiTracer.ts`)

**Features:**
- Cost calculation per model (Grok-4-fast, Grok Vision, Claude 3.5)
- Token usage extraction from OpenRouter responses
- Cache hit/miss tracking
- Duration monitoring
- Structured logging with emojis for dev environments
- Success/failure tracking

**Usage Example:**
```typescript
import { aiTracer } from './aiTracer';

// Track cache hit
await aiTracer.traceCacheHit('viral_pattern', userId, { trendId });

// Track AI call
const startTime = Date.now();
const response = await openai.chat.completions.create({...});
await aiTracer.traceAICall('viral_pattern', 'grok-4-fast', response, startTime, userId);

// Track error
try {
  // ... AI call
} catch (error) {
  await aiTracer.traceAIError('viral_pattern', 'grok-4-fast', error, startTime, userId);
}
```

**Model Pricing (as of 2025-01):**
```typescript
const MODEL_COSTS = {
  'x-ai/grok-4-fast': { input: $0.50, output: $1.50 },       // per 1M tokens
  'x-ai/grok-2-vision-1212': { input: $2.00, output: $10.00 },
  'anthropic/claude-3-5-sonnet': { input: $3.00, output: $15.00 }
};
```

**Log Format:**
```
Development:
üì¶ ‚úÖ AI Call: viral_pattern | Model: grok-4-fast | Cache: HIT | Tokens: 0 | Cost: $0.0000 | Duration: 0ms
ü§ñ ‚úÖ AI Call: viral_pattern | Model: grok-4-fast | Cache: MISS | Tokens: 1245 | Cost: $0.0019 | Duration: 2340ms

Production:
Structured JSON logs to monitoring service
```

---

## ‚è≥ Partially Implemented

### 2. Viral Pattern Service Integration

**Status:** Cache hits are tracked, but AI calls need deeper integration

**What Works:**
```typescript
// Cache hit tracking
if (existingAnalysis && !isExpired) {
  await aiTracer.traceCacheHit('viral_pattern', null, { trendId });
  return existingAnalysis;
}
```

**What Needs Work:**
The `openRouterService.analyzeContent()` method doesn't expose the raw OpenRouter response with usage data. We need to either:

1. **Option A:** Modify openRouterService to return usage metadata
2. **Option B:** Estimate costs based on input/output token counts
3. **Option C:** Create a wrapper around OpenRouter calls that extracts usage

**Recommended Approach:** Option C (least invasive)

---

## üöß Not Yet Implemented

### 3. Full OpenRouter Integration

**Blocker:** Current `openRouterService` methods return domain objects (`ContentAnalysisResult`, `TrendResult[]`) without exposing raw OpenRouter response metadata.

**OpenRouter Response Structure:**
```typescript
{
  id: "gen-1234567890",
  model: "x-ai/grok-2-vision-1212",
  choices: [{
    message: { content: "..." }
  }],
  usage: {
    prompt_tokens: 245,
    completion_tokens: 1000,
    total_tokens: 1245
  }
}
```

**Required Changes:**
```typescript
// Current
async analyzeContent(request): Promise<ContentAnalysisResult>

// Proposed
async analyzeContent(request): Promise<{
  result: ContentAnalysisResult;
  metadata: {
    model: string;
    usage: { prompt_tokens, completion_tokens, total_tokens };
    cached: boolean;
  }
}>
```

### 4. Database Storage for Analytics

**Table Schema (Future):**
```sql
CREATE TABLE ai_call_traces (
  id SERIAL PRIMARY KEY,
  operation_type VARCHAR(50) NOT NULL,
  model VARCHAR(100) NOT NULL,
  user_id VARCHAR REFERENCES users(id),
  cache_hit BOOLEAN NOT NULL,
  tokens_used INTEGER DEFAULT 0,
  cost_usd DECIMAL(10, 6) DEFAULT 0,
  duration_ms INTEGER NOT NULL,
  success BOOLEAN NOT NULL,
  error_message TEXT,
  metadata JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_ai_traces_user_id ON ai_call_traces(user_id);
CREATE INDEX idx_ai_traces_created_at ON ai_call_traces(created_at);
CREATE INDEX idx_ai_traces_operation ON ai_call_traces(operation_type);
```

**Benefits:**
- Cost analytics dashboard
- User-level usage tracking
- Model performance comparison
- Cache hit rate monitoring
- Error pattern detection

**Considerations:**
- High write volume at scale
- Data retention policies needed
- Consider sampling (e.g., 10% of calls)
- Use time-series DB (TimescaleDB) for better performance

### 5. Admin Dashboard Endpoints

**Proposed API:**
```typescript
GET /api/admin/ai-stats?timeframe=day|week|month
Response: {
  totalCalls: 1250,
  cacheHits: 1125,
  totalTokens: 125000,
  totalCostUsd: 18.75,
  averageCostPerCall: 0.015,
  cacheHitRate: 0.90,
  byModel: {
    "grok-4-fast": { calls: 800, cost: 12.00 },
    "grok-2-vision-1212": { calls: 450, cost: 6.75 }
  },
  byOperation: {
    "viral_pattern": { calls: 450, cost: 6.75 },
    "trends": { calls: 800, cost: 12.00 }
  }
}
```

---

## üìã Implementation Checklist

### Phase 1: Core Tracing (CURRENT)
- [x] Create AITracer service with cost calculation
- [x] Define model pricing constants
- [x] Implement structured logging
- [x] Add cache hit tracking to viralPatternService
- [ ] Add wrapper for OpenRouter calls to extract usage
- [ ] Track all AI calls in viralPatternService
- [ ] Track all AI calls in openRouterService

### Phase 2: Database Storage
- [ ] Create ai_call_traces table
- [ ] Implement trace persistence
- [ ] Add data retention policy
- [ ] Create database indexes
- [ ] Add sampling for high-volume operations

### Phase 3: Analytics & Monitoring
- [ ] Build admin dashboard API
- [ ] Create cost analytics queries
- [ ] Add real-time monitoring alerts
- [ ] Implement cost budgets per user
- [ ] Add anomaly detection (cost spikes)

### Phase 4: Optimization
- [ ] Analyze most expensive operations
- [ ] Optimize prompts for token efficiency
- [ ] Implement aggressive caching for common patterns
- [ ] A/B test cheaper models for non-critical operations
- [ ] Add user-level rate limiting

---

## üéØ Current Trace Example

**With Current Implementation:**
```typescript
// viralPatternService.analyzeTrend(123)

// Console output:
üì¶ ‚úÖ AI Call: viral_pattern | Model: cached | Cache: HIT | Tokens: 0 | Cost: $0.0000 | Duration: 0ms

// Structured log:
{
  "operationType": "viral_pattern",
  "model": "cached",
  "userId": null,
  "cacheHit": true,
  "tokensUsed": 0,
  "costUsd": 0,
  "durationMs": 0,
  "success": true,
  "timestamp": "2025-10-05T09:30:45.123Z",
  "trendId": 123
}
```

---

## üí° Immediate Next Steps

### For Full Tracing Implementation:

1. **Modify OpenRouter Service** (`server/ai/openrouter.ts`):
```typescript
// Add metadata return
interface AICallResult<T> {
  data: T;
  metadata: {
    model: string;
    usage?: {
      prompt_tokens: number;
      completion_tokens: number;
      total_tokens: number;
    };
    cached: boolean;
    durationMs: number;
  };
}
```

2. **Update Viral Pattern Service**:
```typescript
const startTime = Date.now();
const result = await openRouterService.analyzeContentWithMetadata(request, userId);

if (result.metadata.cached) {
  await aiTracer.traceCacheHit('viral_pattern', userId);
} else {
  await aiTracer.traceAICall(
    'viral_pattern',
    result.metadata.model,
    result.metadata.usage,
    startTime,
    userId
  );
}
```

3. **Add Cost Alerts**:
```typescript
// In aiTracer.ts
if (costUsd > DAILY_BUDGET_LIMIT) {
  await sendAlert('Cost budget exceeded', { costUsd, limit: DAILY_BUDGET_LIMIT });
}
```

---

## üìä Expected Cost Savings

**Current State (with caching):**
- 90% cache hit rate
- Monthly cost: $4-10 for 1000 users

**With Full Tracing:**
- Identify most expensive operations
- Optimize prompts (reduce tokens by 20-30%)
- Switch cheaper models for non-critical paths
- **Projected savings:** Additional 20-40% reduction
- **New monthly cost:** $2-6 for 1000 users

---

## üîç Debugging & Monitoring

**Development:**
```bash
# Watch AI calls in real-time
tail -f logs/combined.log | grep "AI Call"

# Check cost per operation
grep "viral_pattern" logs/combined.log | grep "Cost:"
```

**Production:**
```bash
# Query aggregated costs (when DB storage added)
SELECT
  operation_type,
  COUNT(*) as calls,
  SUM(tokens_used) as total_tokens,
  SUM(cost_usd) as total_cost,
  AVG(cost_usd) as avg_cost
FROM ai_call_traces
WHERE created_at > NOW() - INTERVAL '1 day'
GROUP BY operation_type;
```

---

## üöÄ Future Enhancements

1. **Token Estimation** - Predict costs before API calls
2. **Smart Model Selection** - Auto-switch to cheaper models when possible
3. **Prompt Compression** - Use techniques like prompt caching
4. **Batch Processing** - Combine multiple analysis requests
5. **User Quotas** - Per-user AI usage limits
6. **Cost Forecasting** - Predict monthly costs based on trends

---

**Status:** ‚úÖ Foundation built, partial integration complete
**Next Sprint:** Full OpenRouter integration + database storage
**Priority:** Medium (nice-to-have for MVP, critical for production scale)
